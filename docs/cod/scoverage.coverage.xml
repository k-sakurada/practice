<statements>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>23</id><start>5013</start><end>5013</end><line>175</line><description>spark.implicits.newProductEncoder[SparkSQLExample.Person](({
  val $u: reflect.runtime.universe.type = scala.reflect.runtime.`package`.universe;
  val $m: $u.Mirror = scala.reflect.runtime.`package`.universe.runtimeMirror(this.getClass().getClassLoader());
  $u.TypeTag.apply[SparkSQLExample.Person]($m, {
    final class $typecreator3 extends TypeCreator {
      def &lt;init&gt;(): $typecreator3 = {
        $typecreator3.super.&lt;init&gt;();
        ()
      };
      def apply[U &lt;: scala.reflect.api.Universe with Singleton]($m$untyped: scala.reflect.api.Mirror[U]): U#Type = {
        val $u: U = $m$untyped.universe;
        val $m: $u.Mirror = $m$untyped.asInstanceOf[$u.Mirror];
        $u.internal.reificationSupport.selectType($m.staticModule(&quot;SparkSQLExample&quot;).asModule.moduleClass, &quot;Person&quot;).asType.toTypeConstructor
      }
    };
    new $typecreator3()
  })
}: reflect.runtime.universe.TypeTag[SparkSQLExample.Person]))</description><symbolName>org.apache.spark.sql.SQLImplicits.newProductEncoder</symbolName><treeName>ApplyToImplicitArgs</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>8</id><start>2427</start><end>2451</end><line>78</line><description>df.select(&quot;name&quot;).show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>17</id><start>4034</start><end>4099</end><line>146</line><description>spark.newSession().sql(&quot;SELECT * FROM global_temp.people&quot;).show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>11</id><start>3024</start><end>3056</end><line>106</line><description>df.groupBy(&quot;age&quot;).count().show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>main</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>2</id><start>1626</start><end>1657</end><line>47</line><description>SparkSQLExample.this.runBasicDataFrameExample(spark)</description><symbolName>SparkSQLExample.runBasicDataFrameExample</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>20</id><start>4736</start><end>4755</end><line>170</line><description>spark.implicits.localSeqToDatasetHolder[Int](collection.this.Seq.apply[Int](1, 2, 3))(spark.implicits.newIntEncoder).toDS()</description><symbolName>org.apache.spark.sql.DatasetHolder.toDS</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>5</id><start>1831</start><end>1882</end><line>55</line><description>spark.read.json(&quot;wasb:///example/data/people.json&quot;)</description><symbolName>org.apache.spark.sql.DataFrameReader.json</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>14</id><start>3402</start><end>3414</end><line>121</line><description>sqlDF.show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>13</id><start>3364</start><end>3397</end><line>120</line><description>spark.sql(&quot;SELECT * FROM people&quot;)</description><symbolName>org.apache.spark.sql.SparkSession.sql</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>main</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>4</id><start>1700</start><end>1712</end><line>50</line><description>spark.stop()</description><symbolName>org.apache.spark.sql.SparkSession.stop</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>22</id><start>4935</start><end>4969</end><line>174</line><description>&quot;wasb:///example/data/people.json&quot;</description><symbolName>&lt;nosymbol&gt;</symbolName><treeName>Literal</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>7</id><start>2275</start><end>2291</end><line>72</line><description>df.printSchema()</description><symbolName>org.apache.spark.sql.Dataset.printSchema</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>16</id><start>3797</start><end>3849</end><line>136</line><description>spark.sql(&quot;SELECT * FROM global_temp.people&quot;).show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>25</id><start>5026</start><end>5041</end><line>176</line><description>peopleDS.show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>10</id><start>2867</start><end>2896</end><line>98</line><description>df.filter(spark.implicits.StringToColumn(scala.StringContext.apply(&quot;age&quot;)).$().&gt;(40)).show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>main</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>1</id><start>1341</start><end>1489</end><line>41</line><description>org.apache.spark.sql.SparkSession.builder().appName(&quot;Spark SQL basic example&quot;).config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;).getOrCreate()</description><symbolName>org.apache.spark.sql.SparkSession.Builder.getOrCreate</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>19</id><start>4508</start><end>4526</end><line>162</line><description>caseClassDS.show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>9</id><start>2614</start><end>2651</end><line>88</line><description>df.select(spark.implicits.StringToColumn(scala.StringContext.apply(&quot;name&quot;)).$(), spark.implicits.StringToColumn(scala.StringContext.apply(&quot;age&quot;)).$().+(1)).show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>18</id><start>4473</start><end>4503</end><line>161</line><description>spark.implicits.localSeqToDatasetHolder[SparkSQLExample.Person](collection.this.Seq.apply[SparkSQLExample.Person](SparkSQLExample.this.Person.apply(&quot;Andy&quot;, 32L)))(spark.implicits.newProductEncoder[SparkSQLExample.Person](({
  val $u: reflect.runtime.universe.type = scala.reflect.runtime.`package`.universe;
  val $m: $u.Mirror = scala.reflect.runtime.`package`.universe.runtimeMirror(this.getClass().getClassLoader());
  $u.TypeTag.apply[SparkSQLExample.Person]($m, {
    final class $typecreator2 extends TypeCreator {
      def &lt;init&gt;(): $typecreator2 = {
        $typecreator2.super.&lt;init&gt;();
        ()
      };
      def apply[U &lt;: scala.reflect.api.Universe with Singleton]($m$untyped: scala.reflect.api.Mirror[U]): U#Type = {
        val $u: U = $m$untyped.universe;
        val $m: $u.Mirror = $m$untyped.asInstanceOf[$u.Mirror];
        $u.internal.reificationSupport.selectType($m.staticModule(&quot;SparkSQLExample&quot;).asModule.moduleClass, &quot;Person&quot;).asType.toTypeConstructor
      }
    };
    new $typecreator2()
  })
}: reflect.runtime.universe.TypeTag[SparkSQLExample.Person]))).toDS()</description><symbolName>org.apache.spark.sql.DatasetHolder.toDS</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>12</id><start>3310</start><end>3346</end><line>118</line><description>df.createOrReplaceTempView(&quot;people&quot;)</description><symbolName>org.apache.spark.sql.Dataset.createOrReplaceTempView</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>main</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>3</id><start>1662</start><end>1694</end><line>48</line><description>SparkSQLExample.this.runDatasetCreationExample(spark)</description><symbolName>SparkSQLExample.runDatasetCreationExample</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>21</id><start>4760</start><end>4792</end><line>171</line><description>primitiveDS.map[Int](((x$1: Int) =&gt; x$1.+(1)))(spark.implicits.newIntEncoder).collect()</description><symbolName>org.apache.spark.sql.Dataset.collect</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>15</id><start>3676</start><end>3709</end><line>133</line><description>df.createGlobalTempView(&quot;people&quot;)</description><symbolName>org.apache.spark.sql.Dataset.createGlobalTempView</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runBasicDataFrameExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>6</id><start>1943</start><end>1952</end><line>58</line><description>df.show()</description><symbolName>org.apache.spark.sql.Dataset.show</symbolName><treeName>Apply</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
<statement><source>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</source><package>&lt;empty&gt;</package><class>SparkSQLExample</class><classType>Object</classType><fullClassName>SparkSQLExample</fullClassName><method>runDatasetCreationExample</method><path>/home/circleci/repo/src/main/scala/SparkSQLExample.scala</path><id>24</id><start>4989</start><end>5021</end><line>175</line><description>spark.read.json(path).as[SparkSQLExample.Person](spark.implicits.newProductEncoder[SparkSQLExample.Person](({
  val $u: reflect.runtime.universe.type = scala.reflect.runtime.`package`.universe;
  val $m: $u.Mirror = scala.reflect.runtime.`package`.universe.runtimeMirror(this.getClass().getClassLoader());
  $u.TypeTag.apply[SparkSQLExample.Person]($m, {
    final class $typecreator3 extends TypeCreator {
      def &lt;init&gt;(): $typecreator3 = {
        $typecreator3.super.&lt;init&gt;();
        ()
      };
      def apply[U &lt;: scala.reflect.api.Universe with Singleton]($m$untyped: scala.reflect.api.Mirror[U]): U#Type = {
        val $u: U = $m$untyped.universe;
        val $m: $u.Mirror = $m$untyped.asInstanceOf[$u.Mirror];
        $u.internal.reificationSupport.selectType($m.staticModule(&quot;SparkSQLExample&quot;).asModule.moduleClass, &quot;Person&quot;).asType.toTypeConstructor
      }
    };
    new $typecreator3()
  })
}: reflect.runtime.universe.TypeTag[SparkSQLExample.Person])))</description><symbolName>org.apache.spark.sql.Dataset.as</symbolName><treeName>ApplyToImplicitArgs</treeName><branch>false</branch><count>0</count><ignored>false</ignored></statement>
</statements>